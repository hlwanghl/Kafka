---
name: Release Checklist
about: Checklist items before a release.
title: ''
labels: ''
assignees: ''

---

# 服务功能测试

- [ ] 写入数据，自定义客户端正常读取
- [ ] 在配置项可自由开启zabbix-agent（会导致服务重启）
- [ ] confd升级到最新版本
- [ ] 查看服务日志
- [ ] 日志轮转
- [ ] Kafka 节点初始创建 __consumer_offset，老版本可能有延迟
- [ ] Heap Dump 文件在 OOM 情况下自动生成（-Xmx32m）

# 集群功能测试

- [ ] **创建**
  - [ ] 创建单个节点和客户端的集群
  - [ ] 创建多个节点的集群
  - [ ] 创建常用硬件配置的集群
  - [ ] 修改常用配置参数，创建集群
  - [ ] 多个集群共用一个zookeeper
  - [ ] 创建集群后，查看kafka manager，问题：有时会出现，kafka manager不能成功管理cluster的问题；该问题已修复
- [ ] 关闭集群并启动集群
- [ ] 删除集群并恢复集群
- [ ] 支持多可用区（四/六节点，分区副本按可用区分布）
- [ ] **横向伸缩**
  - [ ] 增加 client/kafka 节点，数据分布正常，迁移到新主机需手动平衡 (发现 bug：新加节点没有安装arping，会导致mac地址错误，最终会导致服务无法启动)
  - [ ] 删除节点
- [ ] **纵向伸缩**
  - [ ] 扩容：服务正常
  - [ ] 缩容：服务正常
- [ ] **升级**
  - [ ] 消息数据不丢，topic offset 不丢（多区可活仅可在创建应用时选择，升级无效）
  - [ ] 升级后设置日志留存大小限制值，查看日志留存配置生效
- [ ] 切换私有网络
- [ ] 绑定公网 IP(vpc)
- [ ] 基础网络部署
- [ ] 自动伸缩（节点数，硬盘容量）
- [ ] 健康检查和自动重启
- [ ] 服务监控

# 高可用

- [ ] **数据高可用**
  - [ ] 把三节点kafka集群中的一个节点断网，数据正常写入和查询（需要该主机数据有其他备份,单备份情况下需要主机及时恢复）
- [ ] **服务高可用**
  - [ ] 3节点kafka：节点reboot后，待主机启动后，服务可自动启动；可以正常生产和消费消息，测试通过
  - [ ] 节点网络异常，测试通过
  - [ ] 关闭服务后，服务可自动启动，可以正常生产和消费消息，测试通过

# 压力测试

- [ ] **磁盘**
  - [ ] 节点磁盘占满后，该节点的服务状态会显示为不正常
  - [ ] 当一个节点的磁盘占满时，该节点不能进行数据的生产和消费，其他节点仍可以进行正常操作
  - [ ] 节点磁盘占满，关闭启动集群后，磁盘占满的节点服务状态仍显示为不正常，该节点仍不能参与数据的生产和消费，其他节点可以正常使用
  - [ ] 节点磁盘占满，可成功添加节点，添加后，该节点成为新的broker
  - [ ] 删除磁盘未占满节点，可以删除
  - [ ] 删除磁盘占满节点，可以删除
  - [ ] 节点磁盘占满，扩容硬盘后，集群节点恢复正常，可正常进行数据的生产和消费，测试通过

# 性能/基准测试

- [ ] 持续读写平均延迟为2ms(最低配置，备份2)
  >  压测工具：kafka/bin/kafka-producer-pref-test.sh;  kafka-consumer-pref-test.sh

# 系统测试

- [ ] **与 ZooKeeper 集成**
  - [ ] 创建集群时，设置的zookeeper为关闭状态，关闭状态的zookeeper不会显示在可选列表中
  - [ ] 创建集群时，设置的zookeeper网络异常，可以创建kafka集群，但创建后kafka集群服务状态不正常；创建后，恢复zookeeper的网络，kafka集群状态更新为正常，可正>常进行操作
  - [ ] 集群使用过程中，zookeeper网络异常，kafka服务仍显示为正常；之前创建的topic可以正常生产和消费数据；不能创建新的topic；待网络恢复后，可以正常进行操作
  - [ ] 添加删除zookeeper节点，查看kafka manager中的zookeeper 信息，问题： 1、kafka manager中的zookeeper信息未同步； 2、创建kafka时，选择的zookeeper仅包含一个节点A，创建好kafka集群后，为zookeeper添加2个节点B和C；然后再删除zookeeper的节点A和B，删除后，kafka manager报错，不能使用
- [ ] **与 ELK 集成**
  - [ ] kafka消息output至logstash，再至es中，测试通过
  - [ ] logstash生产消息至kafka，测试通过

# Long Run

- [ ] kafka中不停生产消息至logstash中，再至es中，运行16个小时，未出现异常
- [ ] UI界面中循环进行创建集群--增删节点--重启集群--扩容集群--删除集群的操作
- [ ] 在10G存储，且磁盘使用率为95%的集群中，循环进行增删节点--扩容缩容集群--重启集群的操作
